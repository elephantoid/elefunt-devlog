{
  
    
        "post0": {
            "title": "Pychonic : 효율적인 파이썬 코딩!",
            "content": "한창 알고리즘 문제들을 풀면서 제 코드를 다시 보면 너무 지저분하고 또 다른 분들의 숏코드를 보면 와.. 이걸 이렇게 할 수 있구나 싶었습니다. 그러다 DataCamp 의 Efficeint Code라는 수업을 들으며 배운 내용을 공유해보고자 합니다. . &#54952;&#50984;&#51201;&#51064; &#53076;&#46300;&#46976;? . 사실 효율적인 코드의 정의를 어떻게 내리느냐에 따라 앞으로의 내용이 많이 달라질 것 같습니다. 가장 중요한 두가지가 있습니다. . 빠르고 최소 시간의 런타임(소요시간) | 최소의 resource를 활용하는 것 | 파이썬에는 Pythonic한 코드를 작성하라는 팁이 있습니다. . import this . The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren&#39;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you&#39;re Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it&#39;s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let&#39;s do more of those! . Beautiful is better than ugly. 아름다움이 추한 것보다 낫다. . Explicit is better than implicit. 명확함이 함축된 것보다 낫다. . Simple is better than complex. 단순함이 복잡한 것보다 낫다. . Complex is better than complicated. 복잡함이 난해한 것보다 낫다. . Flat is better than nested. 단조로움이 중접된 것보다 낫다. . Sparse is better than dense. 여유로움이 밀집된 것보다 낫다. . Readability counts. 가독성은 중요하다. . Special cases aren&#39;t special enough to break the rules. 규칙을 깨야할 정도로 특별한 경우란 없다. Although practicality beats purity. 비록 실용성이 이상을 능가한다 하더라도. . Errors should never pass silently. 오류는 결코 조용히 지나가지 않는다. Unless explicitly silenced. 알고도 침묵하지 않는 한. . In the face of ambiguity, refuse the temptation to guess. 모호함을 마주하고 추측하려는 유혹을 거절하라. There should be one-- and preferably only one --obvious way to do it. 문제를 해결할 하나의 - 바람직하고 유일한 - 명백한 방법이 있을 것이다. Although that way may not be obvious at first unless you&#39;re Dutch. 비록 당신이 우둔해서 처음에는 명백해 보이지 않을 수도 있겠지만. Now is better than never. 지금 하는 것이 전혀 안하는 것보다 낫다. Although never is often better than right now. 비록 하지않는 것이 지금 하는 것보다 나을 때도 있지만. . If the implementation is hard to explain, it&#39;s a bad idea. 설명하기 어려운 구현이라면 좋은 아이디어가 아니다. If the implementation is easy to explain, it may be a good idea. 쉽게 설명할 수 있는 구현이라면 좋은 아이디어일 수 있다. Namespaces are one honking great idea -- let&#39;s do more of those! 네임스페이스는 정말 대단한 아이디어다. -- 자주 사용하자! . 출처: https://wikidocs.net/7907 . 중요한 내용을 좀 추려보자면 중첩과 누락을 피하고 최대한 명확하고 읽기 쉬운 간단한 코드를 작성해야합니다. . Bulit-in 함수: print range len round enumerate map zip 등이 있습니다. Bulit-in 모듈: os sys itertools collections 등이 있습니다. . 이 과정에서 제가 배우면서 와닿았던 부분들이 있습니다. . for loop을 남발하지 않고 List Comprehension을 통해 간결하게 만드는 것 | Numpy의 브로드 캐스팅을 활용하는 것 | %timeit을 통해 코드의 런타임을 알아볼 수 있습니다. . -r method : run | -n method : loop | -o method : saving output to a variable | . %lsmagic을 이용하면 모든 매직 커맨드를 확인해볼 수 있습니다. . import numpy as np import pandas as pd %timeit -r2 -n10 rand_nums = np.random.rand(1000) . 11.1 µs ± 2.84 µs per loop (mean ± std. dev. of 2 runs, 10 loops each) . times = %timeit -o rand_nums = np.random.rand(1000) . The slowest run took 10.20 times longer than the fastest. This could mean that an intermediate result is being cached. 100000 loops, best of 5: 9.48 µs per loop . print(times.all_runs) print(times.best) print(times.worst) . [0.9632805540001073, 0.9514958920000254, 0.9509307729999819, 0.9479201429999193, 1.0195112180000478] 9.479201429999193e-06 9.669099995335273e-05 . 이렇게 변수에 할당하여 내용을 확인할 수 있습니다. . 재밌게 읽었던 내용중에 list() 와 [] 중에 뭐가 더 빠를까? 에 대한 내용입니다. 어떤 방법이 더 빠를까요? 이름을 명시하는 것보다 []와 같이 literal 구문을 이용하는 것이 더 빠릅니다. 한 번 해보세요! . Code Profiling : Time . 좀 더 자세한 내용과 각 라인 별로 보고 싶을 수도 있잖아요? 그리고 %timeit을 사용하면 1 라인만 확인할 수 있어요. 저희는 def를 이용해 함수를 정의해서 많이 사용하기 때문에 라인별로 어디에서 시간이 오래걸리는지 알 필요가 있습니다. pip install line_profiler를 이용해 설치해주세요 . !pip install line_profiler . Collecting line_profiler Downloading line_profiler-3.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66 kB) |████████████████████████████████| 66 kB 2.4 MB/s Requirement already satisfied: IPython&gt;=0.13 in /usr/local/lib/python3.7/dist-packages (from line_profiler) (5.5.0) Requirement already satisfied: prompt-toolkit&lt;2.0.0,&gt;=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (1.0.18) Requirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (5.1.1) Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (4.4.2) Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (4.8.0) Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (2.6.1) Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (0.7.5) Requirement already satisfied: simplegeneric&gt;0.8 in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (0.8.1) Requirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython&gt;=0.13-&gt;line_profiler) (57.4.0) Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;IPython&gt;=0.13-&gt;line_profiler) (1.15.0) Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;IPython&gt;=0.13-&gt;line_profiler) (0.2.5) Requirement already satisfied: ptyprocess&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect-&gt;IPython&gt;=0.13-&gt;line_profiler) (0.7.0) Installing collected packages: line-profiler Successfully installed line-profiler-3.4.0 . def convert_units(herose, hts, wts): new_hts =[ht * 0.39370 for ht in hts] new_wts =[wt * 2.20462 for wt in wts] hero_data = {} for i, hero in enumerate(herose): hero_data[hero] = (new_hts[i], new_wts[i]) return hero_data . convert_units(heroes, hts, wts) . {&#39;Batman&#39;: (74.01559999999999, 209.4389), &#39;Superman&#39;: (75.19669999999999, 222.66661999999997), &#39;Wonder Woman&#39;: (72.0471, 163.14188)} . %load_ext line_profiler # 나 이제 라인 프로파일러 사용할거야 하고 알려줍니다 %lprun -f # 함수를 볼거야 하고 알려줍니다. . %load_ext line_profiler %lprun -f convert_units . The line_profiler extension is already loaded. To reload it, use: %reload_ext line_profiler . . 이렇게 보면 그냥 잘모르겠죠.. 값을 넣어줍니다 식은 %lprun -f 함수명 함수명(값) 입니다 . %reload_ext line_profiler %lprun -f convert_units convert_units(heroes, hts, wts) . . 이제 확실히 알수 있겠죠? 각 라인이 몇번 실행 됐는지 어느 라인에서 시간이 오래걸렸고(%) 그 라인이 어느 구문인지 알 수 있습니다. . Code profiling : Memory . 시간을 확인해봤으니 이제 리소스를 얼마나 잡아먹고 있나 확인해보겠습니다. . pip install memory_profiler해주세요. 방법은 위와 동일합니다! . !pip install memory_profiler . Collecting memory_profiler Downloading memory_profiler-0.60.0.tar.gz (38 kB) Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8) Building wheels for collected packages: memory-profiler Building wheel for memory-profiler (setup.py) ... done Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31285 sha256=8fca6dd0956c7d8db0c21bd2b1fd3a3cd5d968f8a7ffb1a2142c140ff0a2d516 Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f Successfully built memory-profiler Installing collected packages: memory-profiler Successfully installed memory-profiler-0.60.0 . %load_ext memory_profiler %mprun -f convert_units convert_units(heroes, hts, wts) . The memory_profiler extension is already loaded. To reload it, use: %reload_ext memory_profiler ERROR: Could not find file &lt;ipython-input-15-c2659a0c0e8b&gt; NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment. . %mprun can only be used on functions defined in physical files, and not in the IPython environment . 아아... 제가 현재 코랩환경에서 하고 있어서 못보여드리네요..😥😥 파이참이나 Ipython 환경이 아니신 분들은 한 번 해보세요 MiB 기준으로 이전행과 얼만큼의 메모리를 사용하고 있는지 알 수 있습니다. . Combining, Counting, iterating . 간단하게 작은 데이터셋을 이용하여 설명하도록 하겠습니다. 아래 1번 코드는 제가 그냥 코딩을 한 것입니다. 2번은 zip이라는 함수를 사용하여 더 간편하게 바꿀 수 있습니다. . names = [&#39;피카츄&#39;, &#39;파이리&#39;, &#39;꼬북이&#39;] hps = [45, 39, 44] combined = [] for idx , pokemon in enumerate(names): combined.append((pokemon, hps[idx])) print(combined) . [(&#39;피카츄&#39;, 45), (&#39;파이리&#39;, 39), (&#39;꼬북이&#39;, 44)] . combined_zip = zip(names, hps) print(combined) . [(&#39;피카츄&#39;, 45), (&#39;파이리&#39;, 39), (&#39;꼬북이&#39;, 44)] . 이외에도 다양한 함수들이 있습니다. namedtuple : tuple subclasses with named fields deque : list-like container with fast appends and pops Counter : dict for counting hashable objects OrderedDict : dict that retains order of entries defaultdict : dict that calls a factory function to supply missing values deque : list-like container with fast appends and pops . 모두 다 실습해 볼 수는 없으니 양해를 부탁드립니다 🤕 . 예를 들어, 각각의 아이템이 총 몇개씩 들어가 있는지 궁금할 때가 있습니다. 가끔 코딩 테스트를 준비하며 백준 온라인 저지에 있는 문제를 풀다 보면 나오는 문제기도 합니다. . from collections import Counter print(Counter(types)) . Counter({&#39;Water&#39;: 66, &#39;Normal&#39;: 64, &#39;Bug&#39;: 51, &#39;Grass&#39;: 47, &#39;Psychic&#39;: 31, &#39;Rock&#39;: 29, &#39;Fire&#39;: 27, &#39;Electric&#39;: 25, &#39;Ground&#39;: 23, &#39;Fighting&#39;: 23, &#39;Poison&#39;: 22, &#39;Steel&#39;: 18, &#39;Ice&#39;: 16, &#39;Fairy&#39;: 16, &#39;Dragon&#39;: 16, &#39;Ghost&#39;: 13, &#39;Dark&#39;: 13}) . collections에는 이 뿐만 아니라 아래의 함수들도 제공하고 있습니다. 저 같은 경우는 경우의 수 조합을 구할 때 combinations 함수를 자주 이용하곤 했습니다. . Innite iterators: count , cycle , repeat | Finite iterators: accumulate , chain , zip_ longest , etc. | Combination generators: product , permutations , combinations | . . 또 중복제거에 탁월한 set 함수도 있습니다. 그런데 여기에 SQL에서 사용했던 JOIN과 비슷한 역할을 해주는 메소드가 있습니다. . | 해당 메소드는 Set type에서만 사용 가능합니다. . intersection() : all elements that are in both sets / 교집합 | difference() : all elements in one set but not the other / A | symmetric_difference() : all elements in exactly one set/ A - AnB | union() : all elements that are in either set / 합집합 | . Loop &#51228;&#44144;&#54616;&#44592; . for와 while는 정말 자주 사용하기도 하고 안쓸려고해도 안쓸수가 없습니다. 그래도 최대한 쓰지 않아도 될 때는 대체하는 것이 Pytonic한 코드라고 할 수 있습니다. 3가지 방법으로 비교해볼려고 합니다. . for loop | List Comprehension | Built-in map() funtion | %%timeit totals = [] for row in poke_stats: totals.append(sum(row)) . 100000 loops, best of 5: 11.1 µs per loop . %timeit totals_comp = [sum(row) for row in poke_stats] . 100000 loops, best of 5: 8.65 µs per loop . %timeit totals_map = [*map(sum, poke_stats)] . 100000 loops, best of 5: 6.32 µs per loop . 결과가 보이시나요?? 이렇게 시간을 단축 시킬 수 있습니다 ✈ .",
            "url": "https://elephantoid.github.io/elefunt-devlog/python/2022/01/12/Efficeint-Pythonic-code.html",
            "relUrl": "/python/2022/01/12/Efficeint-Pythonic-code.html",
            "date": " • Jan 12, 2022"
        }
        
    
  
    
  
    
        ,"post2": {
            "title": "2021년 회고",
            "content": "Work . 시 청년인턴(3/2~10/31) | . K: 8개월간 무탈하게 근무 함 P: 인턴 기간 중 취업을 하지 못했던 점 T: 자소서 및 포트폴리오를 잘 준비해두면서 병렬전략으로 면접을 많이 가자 . Study . cs231n (4~8) K: 무사히 모든 lecture를 수료 | P: 중간중간 붕 떠버린 기간, 완벽히 이해하지 못하고 넘어간 것들(대략적으로만 이해) | T: 복습하며 부족한 부분 메꾸기(blog update) | . | IT 시사 기술 이슈 K: 매주 금요일 마다 다양한 IT 시사 기술 동향을 파악하고 있다. | P: 가끔 할게 없어서 귀찮을 때가 있었다. | T: 내가 공부하는 도메인 방향의 최신 트렌드를 찾아 공유하자. | . | dsf - ML specialist (가짜연구소) K: 단순히 주어진 코스 외에 추가적으로 공부하고 싶은 것을 공부하고 있다.(SQL, Efficient coding, etc) | P: X | T: X | . | 체인지업(리팸) K: 체인지업 서브 스터디를하며 면접과 자소서 첨삭 기회에 앞으로 어떻게 해야할지 방향성을 잡았다. | P: 메인 스터디를 참석하지 못한 것이 아쉬움 | T: 각각의 경험을 3C4P로 재정리하고 그것을 자소서에 녹여내자(완) | . | 데이터 분석 취업 스터디(리팸) K: 매주 약속 시간을 잘 지키고 의욕이 많다. | P: 다양한 것들을 해보자 해보자 했지만 제대로 완료하지 못한 것들이 많다. | T: 의견을 조율하며 서로 최소한 할 수 있는 것들을 차근차근 해나가자. | . | . Competition . 코인예측 K: 새로운 것을 찾아 봤다(Prophet) | P: Private 점수와 Public이 매우 큰 차이를 보였다. 과적합된 모델을 만들었다. | T: 좀 더 일반화에 신경쓰며 점수에 너무 크게 연연하지 않도록 하자 | . | COVID-19 object detection K: Object detection에 한 걸을 가까워지며 DICOM 파일을 다루는 경험을 했다. | P: Study를 만들어 했지만 저조한 참여율을 보였다. 그로인해 나 까지도 끝까지 책임지지 못했다. | T: 팀원들의 수준을 고려해 랭커들이 올린 자료를 보고 코드 리뷰하는 방식으로 나아갔으면 더 좋았을 것이다. | . | MAIC segmentation K: | P: 인원이 많아 역할 분담이 애매했다. 하는 사람만 하는 구조였다. 잘 모이기 쉽지 않았다. 개인적으로는 다른일들과 겹쳐 제대로 참여하지 못했다. | T: 의료영상에 대한 공부를 했지만 그것만으로는 부족했다. 관련 논문을 읽고 좀 더 잘 이해한 뒤 구현에 힘을 쏟았으면 좋았을 것이다. | . | CCTV 보안 영상 이미지 object detection K: 팀원을 모집하여 참가했으며 10위라는 성적을 받았다. | P: Git을 사용하지 못하는 환경에서 팀원들과의 의사소통이 활발하지 못했다. | T: 팀장으로서 책임감을 갖고 아이스 브레이킹 후에 더 많은 대화를 했어야 했다. 팀원에게 어떤 문제가 생긴다면 다 같이 도와서 해결할 수 있도록 도와줄 것이다. 내가 부족하더라도 팀으로서 함께 노력한다면 더 좋은 결과를 얻을 수 있을 것이다. | . | 물류 유통량 예측 K: 코인예측 대회와 상반되게 모델이 과적합 되지 않았다. 그리고 새로운 라이브러리들을 사용해보고 DataCamp에서 배운 내용을 녹여내서 좋았다. | P: NN도 함께 넣으면 좋았을 것 같았지만 방법을 찾지 못했다. | T: 조금 더 집중하자. | . | . Reading . 왜 일하는가? | Code | 피터 드러커 자기경영 노트 | 그릿 | 돈의 역사 | 에이트 : 인공지능에게 대체되지 않는 나를 만드는 법 | 뼈 있는 아무 말 대잔치 | 당신의 뇌를 고칠 수 있다. | 그로스 아이큐 | 벌거벗은 통계학 . | K: 빡독이라는 커뮤니티에서 한 달간 주최자로서 매일 새벽 6시에 독서를 했다. 값진 경험이었다. | P: 독서의 중요성을 알면서도 이것저것 바빠지니 미뤘다. | T: 이번년도에는 최소 월 1권의 책을 독서 후 기록해보자 | . Health . Strong lift 5x5 | GVT 10x10 | 크로스핏 (3 months) | 러닝 . | K: 운동을 해야한다는 생각으로 계속 했다. 30분 달리기를 완주했다. 웨이트를 하면서도 자세에 대해 계속 고민하고 맞는지 체크하는 과정은 도움이 됐다. | P: 중간중간 운동의 공백기가 있다. 그래서 다시 시작할 때는 처음으로 돌아간 느낌이였다. | T: 멈추지 말자. 킵고잉 | .",
            "url": "https://elephantoid.github.io/elefunt-devlog/2021/12/27/2021_Retrospective.html",
            "relUrl": "/2021/12/27/2021_Retrospective.html",
            "date": " • Dec 27, 2021"
        }
        
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
        ,"post15": {
            "title": "Fastpages comment기능 활성화",
            "content": "Comments &#44592;&#45733; &#50948;&#52824; . fastpage의 포스트 하단에 보시면 Comment 기능이 있습니다. 하지만 바로 사용이 가능한 것은 아닙니다. 활성화를 시켜줘야 다른 사람들이 코멘트를 작성할 수 있습니다. . 만약 코멘트 기능을 활성화하지 않은 경우에는 아래와 같은 메세지를 볼 수 있습니다. . Comments &#44592;&#45733; &#54876;&#49457;&#54868; &#54616;&#44592; . 방법은 매우 간단하고 비용도 무료입니다. Github App에 있는 utterances 🔮 이 친구를 사용할 것입니다. . https://github.com/apps/utterances 일단 위 페이지에 접속해줍니다. . 방법은 매우 간단합니다 . 우측에 보이는 초록색 버튼 Configure를 눌러서 앱을 추가한다 | fastpages를 포함하고 있는 repo만 활성화 시킨다. | 한 번 함께 해볼게요 . . 이 화면이 보이신다면 잘 오셨습니다. 저는 이미 설정을 완료해서 Configure라고 나오지만 처음 접속했을 때는 초록색 버튼이였습니다. 클릭해주세요 . . 그 다음으로 보이는 화면은 어디에다가 utterances를 설치할거냐고 물어보는 것인데 fastpages를 만든 계정에 하셔야합니다. 저는 elephantoid계정에 repo를 생성했기 때문에 elephantoid를 클릭했습니다. . . 이제 마지막입니다. 여기까지 오셨다면 이미 끝난 것과 다름 없습니다. 빨간색 박스안에 있는 부분을 수정할 것입니다. 초기 setting은 All repo로 되어있지만 Only select repositories를 누르고 본인이 fastpages를 담아둔 repo를 선택합니다. 마지막으로 가장 중요한 것 Save버튼을 꼭 눌러주세요!! . . 좀 더 자세한 내용을 알고싶으시다면 여기 . 오늘 포스트가 도움이 되셨으면 좋겠습니다. 뭔가 잘 안되실 경우에는 댓글 달아주세요! .",
            "url": "https://elephantoid.github.io/elefunt-devlog/blog-setting/2021/06/17/fastpages-comment%EA%B8%B0%EB%8A%A5-%ED%99%9C%EC%84%B1%ED%99%94.html",
            "relUrl": "/blog-setting/2021/06/17/fastpages-comment%EA%B8%B0%EB%8A%A5-%ED%99%9C%EC%84%B1%ED%99%94.html",
            "date": " • Jun 17, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "cs231n 7강 Review",
            "content": "Model Ensembles . 독립적으로 N개의 모델을 훈련 | 결과는 N개의 모델 결과의 평균을 사용 | 모델의 개수가 늘어날수록 overfitting을 줄어들고 성능은 조금씩 향상 --&gt; 일반적으로 2% 향상 . Same model, different initializations 교차 검증을 사용하여 가장 좋은 하이퍼 파라미터를 결정한 다음 가장 좋은 하이퍼 파라미터 세트로 여러 모델을 훈련 시키되 다른 임의 초기화를 사용하십시오. 이 접근법의 위험은 다양성이 초기화 때문이라는 것입니다 | . Top models discovered during cross-validation 교차 검증을 사용하여 최상의 하이퍼 파라미터를 결정한 다음 상위 몇 개 (예 : 10 개)의 모델을 선택하여 앙상블을 구성합니다. 이것은 앙상블의 다양성을 향상 시키지만 차선의 모델을 포함 할 위험이 있습니다. 실제로 교차 검증 후 모델을 추가로 재 학습 할 필요가 없으므로 수행하기가 더 쉬울 수 있습니다. | . Different checkpoints of a single model training cost가 매우 비싸다면(소요시간, 장비 등), 단일 네트워크 학습 도중 중간 모델들을 저장하고 앙상블로 사용할 수 있습니다. 여러 체크 포인트에서 나온 예측값들을 평균을 내서 사용합니다. 분명히 이 접근법은 다양성이 부족하지만 실제로 합리적으로 잘 작동합니다. 이 방법의 장점은 매우 저렴하다는 것입니다. 가장 우측에서 그래프는 Learning rate를 엄청 올렸다 내렸다를 반복합니다. 이 방식을 통해 손실 함수에 다양한 지역에서 수렴할 수 있도록 해줍니다 | . Running average of parameters during training 마지막 요점과 관련하여 거의 항상 성능의 추가 비율을 얻는 저렴한 방법은 훈련 중에 이전 가중치의 기하 급수적으로 감소하는 합계를 유지하는 네트워크 가중치의 두 번째 사본을 메모리에 유지하는 것입니다. 이렇게하면 지난 몇 번의 반복에서 네트워크 상태의 평균을 구할 수 있습니다. 마지막 몇 단계에 걸친 가중치의이 &quot;부드러운&quot;버전이 거의 항상 더 나은 유효성 검사 오류를 달성한다는 것을 알 수 있습니다. 염두에 두어야 할 대략적인 직관은 목표가 그릇 모양이고 네트워크가 모드를 뛰어 넘고 있으므로 평균이 모드에 더 가까울 가능성이 더 높다는 것입니다. | . How to imporve single-model performance? . Regularization 정규화는 우리가 모델에 어떤 data를 추가할 때 모델이 training data에 fit되게 하는 것을 막아줍니다. . 앞선 강의에서 이미 몇가지 regularization 기법들을 봤습니다. 보통 Loss에 항을 삽입하는 방식이였습니다. . 사실 L2 regularization은 Neural network에서 그다지 좋은 성능을 보이지 않습니다. 가장 많이 사용하는 regularization은 바로 Drop out입니다. . Drop out . CNN을 배울 때 이미 배우셨을 수도 있습니다. 방식은 매우 간단합니다. forward pass과정에서 임의로 일부 뉴런을 0으로 만드는 것입니다. . 일단 한 레이어의 출력을 전부 구하기 | 랜덤하게 일부를 0으로 만들기 | 그 결과값을 다음 레이어로 넘기기 | Conv net에서는 전체 feature map에서 dropout를 시행하여 여러 channel중에 일부를 dropout시킬 수도 있습니다 . import numpy as np . . p=0.5 #얼마만큼 남길지, 값이 높을수록 0으로 만드는 비율이 줄어듭니다. def train_step(X): H1 = np.maximum(0, np.dot(W1, X)+b1) U1 = np.random.rand(*H1.shape) &lt; p H1 *= U1 #drop H2 = np.maximum(0, np.dot(W2, H1)+b2) U2 = np.random.rand(*H2.shape) &lt; p H2 *= U2 #drop output= np.dot(W3, H2)+b3 . 일부 값들을 0으로 만들면서 네트워크를 심하게 훼손한다고 생각할 수 있습니다. 근데 왜 이 방법이 좋은 것일까요? . 특징들 간의 상호작용(co-adaptation)을 방지합니다. 예를들어 고양이를 분류하는 네트워크에서 어떤 feature는 눈,코,입,귀,꼬리 등을 담당할텐데 이것들을 취합해서 고양이인지 아닌지를 분류합니다.Drop out은 이 때 일부 feature에만 의존하지 못하게 해줍니다. . 또한, Dropout의 새로운 해석은 단일 모델로 앙상블 효과를 가질 수 있다는 것입니다. 일부 뉴런들이 죽으면서 원본 모델의 서브셋 모델들이 여러가지 생기는 것처럼 보이지 않나요? 따라서 Dropout은 서로 파라미터를 공유하는 서브네트워크 앙상블을 동시에 학습시키는 것이라 생각할 수 있습니다. 사실 뉴런 개수의 따라 학습할 모델수가 기하급수적으로 증가하기 때문에 모든 서브네트워크를 사용하는건 사실상 불가능합니다. . . test시에 랜덤하게 들어가는 drop out은 좋지 않습니다. 오늘은 잘 분류하다가 내일은 또 잘못 분류하면 여간 골치아픈게 아닐테니까요. . 대신 그 임의성(randomness)을 average out시킵니다. 사실 밑에 적분식을 다루기 좀 까다롭습니다. 다행히 dropout의 경우에는 일종의 locally cheap한 방법을 이용해 위 적분식을 근사화시킬 수 있습니다. . . dropout(p=0.5)를 적용해서 학습한다고 가정해 봅시다 train time에서의 기댓값을 위와 같이 구할 수 있습니다. dropout mask에는 4가지 경우의 수([0,0],[0,1],[1,0],[1,1])가 존재합니다. 그 후 4개의 마스크에 대해 평균화 시켜줍니다. 이 부분에서 test/train 간의 기댓값이 서로 상이합니다. 여기서 stochasticity를 사용하지 않는 가장 쉬운 방법은 test에 p를 출력 네트워크에 곱하여 똑같이 만들어 줍니다. .",
            "url": "https://elephantoid.github.io/elefunt-devlog/jupyter/2021/06/16/cs231n-7.html",
            "relUrl": "/jupyter/2021/06/16/cs231n-7.html",
            "date": " • Jun 16, 2021"
        }
        
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
        ,"post32": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://elephantoid.github.io/elefunt-devlog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post33": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://elephantoid.github.io/elefunt-devlog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "about me . 안녕하세요 elefunt입니다. .",
          "url": "https://elephantoid.github.io/elefunt-devlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://elephantoid.github.io/elefunt-devlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}